{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edc17827",
   "metadata": {},
   "source": [
    "# HW1 - Classification models in sklearn\n",
    "\n",
    "You'll be building a few classifier models and using some of the tech tools we learned about in Modules 1 and 2. \n",
    "\n",
    "## The Raw Data\n",
    "\n",
    "The data is the the KC housing data. **I've made all the necessary data files available to you\n",
    "in the assignment folder.**\n",
    "\n",
    "Kaggle source: https://www.kaggle.com/harlfoxem/housesalesprediction\n",
    "\n",
    "Basic data dictionary\n",
    "\n",
    "https://geodacenter.github.io/data-and-lab//KingCounty-HouseSales2015/\n",
    "\n",
    "Link to discussion item meaning of CONDITION and GRADE fields:\n",
    "\n",
    "https://www.kaggle.com/harlfoxem/housesalesprediction/discussion/141767\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b2bda9-61ef-45ea-a67b-4bedba8f63be",
   "metadata": {},
   "source": [
    "## Preliminary Data Prep\n",
    "In order to use this data for a classification problem, I did some data prep work. Our target variable is a new variable that I created called `price_gt_1M` which is a binary variable:\n",
    "\n",
    "* 1 - house price is greater than or equal to 1 million dollars\n",
    "* 0 - house price is less than a million dollars\n",
    "\n",
    "The data for this classification problem can be found in `./data/kc_house_data_classification.csv`.\n",
    "\n",
    "If you want to see my data prep code, see the `hw1_sklearn_dataprep.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a3b77-cd10-454e-bb65-cebbfb51ae3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Problem\n",
    "\n",
    "Our overall goal is to build classifier models to predict `price_gt_1M` using the the other variables. You must use sklearn Pipelines that contain your preprocessing steps and your model estimation step. We did this in the class notes.\n",
    "\n",
    "You should do your work in a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78147e4-e1c0-4175-ab38-c05b52514037",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Task 1 - Folder structure\n",
    "\n",
    "Start by creating a new project folder structure with the `cookiecutter-datascience-simple` template that I covered in Module 1. Put the data files into an appropriate folder and put this notebook in the main project folder. Any additional notebooks and/or Python files you end up creating should go in the main project folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225ea0e1-f002-4cc3-a8b3-847872f89d01",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Task 2 - Version control\n",
    "\n",
    "Put your new project folder under version control using git. You should **NOT** track the data file. You must track all notebooks, Python scripts or additional text files you end up creating. Put appropriate information into your readme file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef43a51-cc77-4fb0-863e-ec3f4a74a646",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Task 3 - EDA\n",
    "\n",
    "I suggest you start by reading the csv file into a pandas dataframe. I called my dataframe, `housing_df`.\n",
    "Then start with some basic EDA. You can certainly use automated tools such as pandas-profiling, skimpy or SweetViz as I showed in the class notes. Remember, when you run some of those tools, you **must** have your notebook open in the classic Jupyter Notebook interface (and **NOT** in Jupyter Lab) Check their docs to see if Jupyter Lab is supported yet. I pip installed SweetViz and it seems to be working fine now with Jupyter Lab. As we've seen, the reports get created as HTML documents. These should go in your output folder within your project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582d03d2-2abe-4a32-bcce-962463de8ef0",
   "metadata": {},
   "source": [
    "#### Adding magic command for auto-reloading packages in jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2750df24-8304-4d14-8fbc-9581bddcf303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304384d7-d47c-4d5e-b750-31ba8efd0dde",
   "metadata": {},
   "source": [
    "#### Importing libraries that we'll be using and adding additional magic command for showing plots in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7be4f8bd-4b86-4225-844f-a0eed3173eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sweetviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b742f4ec-7478-4093-a2df-3224eece9cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For showing plots in jupyter lab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0b99b1-c958-4a85-8bce-0214bdcd142c",
   "metadata": {},
   "source": [
    "#### Reading data file and creating sweetviz report from it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae376ce7-1dc6-468b-8ae2-4ea68f1c1dc9",
   "metadata": {},
   "source": [
    "##### Classification csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "011e3337-3248-406e-9560-5621e4404fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>price_gt_1M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \\\n",
       "0             3       1.00         1180      5650     1.0           0     0   \n",
       "1             3       2.25         2570      7242     2.0           0     0   \n",
       "2             2       1.00          770     10000     1.0           0     0   \n",
       "3             4       3.00         1960      5000     1.0           0     0   \n",
       "4             3       2.00         1680      8080     1.0           0     0   \n",
       "...         ...        ...          ...       ...     ...         ...   ...   \n",
       "21608         3       2.50         1530      1131     3.0           0     0   \n",
       "21609         4       2.50         2310      5813     2.0           0     0   \n",
       "21610         2       0.75         1020      1350     2.0           0     0   \n",
       "21611         3       2.50         1600      2388     2.0           0     0   \n",
       "21612         2       0.75         1020      1076     2.0           0     0   \n",
       "\n",
       "       condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
       "0              3      7        1180              0      1955             0   \n",
       "1              3      7        2170            400      1951          1991   \n",
       "2              3      6         770              0      1933             0   \n",
       "3              5      7        1050            910      1965             0   \n",
       "4              3      8        1680              0      1987             0   \n",
       "...          ...    ...         ...            ...       ...           ...   \n",
       "21608          3      8        1530              0      2009             0   \n",
       "21609          3      8        2310              0      2014             0   \n",
       "21610          3      7        1020              0      2009             0   \n",
       "21611          3      8        1600              0      2004             0   \n",
       "21612          3      7        1020              0      2008             0   \n",
       "\n",
       "       zipcode      lat     long  sqft_living15  sqft_lot15  price_gt_1M  \n",
       "0        98178  47.5112 -122.257           1340        5650            0  \n",
       "1        98125  47.7210 -122.319           1690        7639            0  \n",
       "2        98028  47.7379 -122.233           2720        8062            0  \n",
       "3        98136  47.5208 -122.393           1360        5000            0  \n",
       "4        98074  47.6168 -122.045           1800        7503            0  \n",
       "...        ...      ...      ...            ...         ...          ...  \n",
       "21608    98103  47.6993 -122.346           1530        1509            0  \n",
       "21609    98146  47.5107 -122.362           1830        7200            0  \n",
       "21610    98144  47.5944 -122.299           1020        2007            0  \n",
       "21611    98027  47.5345 -122.069           1410        1287            0  \n",
       "21612    98144  47.5941 -122.299           1020        1357            0  \n",
       "\n",
       "[21613 rows x 19 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_class_df = pd.read_csv(\"./data/kc_house_data_classification.csv\")\n",
    "housing_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc905e73-4973-4ea0-a3e7-a58d6fe30d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 19 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   bedrooms       21613 non-null  int64  \n",
      " 1   bathrooms      21613 non-null  float64\n",
      " 2   sqft_living    21613 non-null  int64  \n",
      " 3   sqft_lot       21613 non-null  int64  \n",
      " 4   floors         21613 non-null  float64\n",
      " 5   waterfront     21613 non-null  int64  \n",
      " 6   view           21613 non-null  int64  \n",
      " 7   condition      21613 non-null  int64  \n",
      " 8   grade          21613 non-null  int64  \n",
      " 9   sqft_above     21613 non-null  int64  \n",
      " 10  sqft_basement  21613 non-null  int64  \n",
      " 11  yr_built       21613 non-null  int64  \n",
      " 12  yr_renovated   21613 non-null  int64  \n",
      " 13  zipcode        21613 non-null  int64  \n",
      " 14  lat            21613 non-null  float64\n",
      " 15  long           21613 non-null  float64\n",
      " 16  sqft_living15  21613 non-null  int64  \n",
      " 17  sqft_lot15     21613 non-null  int64  \n",
      " 18  price_gt_1M    21613 non-null  int64  \n",
      "dtypes: float64(4), int64(15)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "housing_class_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14115d5d-bbd2-4479-b5e4-ed0fd9181858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done! Use 'show' commands to display/save.   |███████████████████████████████████████████████████████████████████| [100%]   00:00 -> (00:00 left)\n"
     ]
    }
   ],
   "source": [
    "housing_class_df_report = sweetviz.analyze(housing_class_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8628e4e1-de2e-4a16-9a96-b7792d1db579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report ./output/housing_class_df_sweetviz_report.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "housing_class_df_report.show_html(\"./output/housing_class_df_sweetviz_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ebd035-5afa-48e0-8a7e-e25b7bbe28b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Task 4 - Categorize feature types\n",
    "\n",
    "As we did in the Pump it Up class notes, we are going to need to create a list of categorical variables and a list of numeric variables so that we\n",
    "can apply the appropriate pre-processing to each. In the notes we used the data type of the columns to create lists of numeric and categorical variables. That's not necessarily going to work here as all the variables will come in as numeric. So, you'll have to come up with another way to create lists of the categorical variables and the numeric variables. \n",
    "\n",
    "Since we are using regularization, all of the numeric variables will need to rescaled using the `StandardScaler`. You'll do this later as part of the `Pipeline`. For any variables that you decide should be treated as categorical in your models, use the `OneHotEncoder` on them in the preprocessing stage.\n",
    "\n",
    "Be careful, just because a variable has a numeric datatype in the pandas dataframe, it does **not** mean that it's necessarily a numeric variable in the context of the classification models. Think about each column and look at your EDA reports and decide whether or not it's truly numeric or needs to be treated as categorical data in the models.  \n",
    "\n",
    "Even though our target variable, `price_gt_1M`, is categorical, you do **NOT** need to do any preprocessing on it. As I mentioned in our class notes, scikit-learn will automatically detect that and will do any encoding needed on its own.\n",
    "\n",
    "Finally, you'll partition the dataset into training and test datasets for modeling: \n",
    "\n",
    "* I broke up the `housing_df` into two separate dataframes that I called `X` and `y`, to use in the models. Here's my code for that:\n",
    "\n",
    "```\n",
    "X = housing_df.iloc[:, 0:18]\n",
    "y = housing_df.iloc[:, 18]\n",
    "```\n",
    "\n",
    "* Please use the following code for your data partitioning so that we all end up with the same training and test split:\n",
    "\n",
    "```\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=73)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f61386c-e293-428a-a183-ba87f3271199",
   "metadata": {},
   "source": [
    "#### Choosing categorical feature types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0efb60-eef9-44f3-b874-f483d7e25ab9",
   "metadata": {},
   "source": [
    "The following features/columns will be classified as categorical data:\n",
    "- waterfront\n",
    "- view\n",
    "- condition\n",
    "- grade\n",
    "- zipcode\n",
    "\n",
    "`waterfront` takes on binary values indicating if the property has a waterfront (1) or not (0). \n",
    "\n",
    "`view` is an index of how good the view of the property is, from 0 to 4. This can be considered discrete numerical as well but the subjective nature of how good it is makes me want to classify it as categorical for now. <br>\n",
    "\n",
    "`condition` describes the condition of the house, ranked from 1 to 5.\n",
    "\n",
    "`grade` is defined as 'classification by construction quality which refers to the types of materials used and the quality of workmanship. Buildings of better quality (higher grade) cost more to build per unit of measure and command higher value.' \n",
    "\n",
    "`zipcode` is self-explanatory and describes general location so I don't count it as numerical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03e91390-2690-4142-8131-41db819c53eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bedrooms           int64\n",
       "bathrooms        float64\n",
       "sqft_living        int64\n",
       "sqft_lot           int64\n",
       "floors           float64\n",
       "waterfront         int64\n",
       "view               int64\n",
       "condition          int64\n",
       "grade              int64\n",
       "sqft_above         int64\n",
       "sqft_basement      int64\n",
       "yr_built           int64\n",
       "yr_renovated       int64\n",
       "zipcode            int64\n",
       "lat              float64\n",
       "long             float64\n",
       "sqft_living15      int64\n",
       "sqft_lot15         int64\n",
       "price_gt_1M        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking dtypes\n",
    "housing_class_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c9067426-f9ab-4357-9176-3307f6365f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 7, 8, 13]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a list for the index of `view` to `above` and adding the index for `zipcode`\n",
    "categorical_cols = [col for col in range(5, 9)]\n",
    "categorical_cols.append(13)\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a2b5a2-a64a-4119-991c-032b19a54995",
   "metadata": {},
   "source": [
    "#### Choosing numerical feature types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cafe05-4e67-4097-bbeb-30bfa80705f6",
   "metadata": {},
   "source": [
    "The rest of the fields not classified sa categorical will be classified as numerical. The list is comprised of:\n",
    "- price\n",
    "- bedrooms\n",
    "- bathrooms\n",
    "- sqft_liv\n",
    "- sqft_lot\n",
    "- floors\n",
    "- sqft_above\n",
    "- sqft_basmt\n",
    "- yr_built\n",
    "- yr_renov\n",
    "- lat\n",
    "- long\n",
    "- squft_liv15\n",
    "- squft_lot15\n",
    "\n",
    "`squft_liv15` is defined as the average size of interior housing living space for the closest 15 houses, in square feet.\n",
    "\n",
    "`squft_lot15` is defined as the average size of land lots for the closest 15 houses, in square feet.\n",
    "\n",
    "`lat` stands for latitude while `long` stands for longitude; these are geographical features but since they are continuous and numerical I will consider them numerical.\n",
    "\n",
    "The rest are self-explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c775a323-a965-4d62-8751-d3fedcf7f673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 9, 10, 11, 12, 14, 15, 16, 17]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking everything that's not categorical and dropping target variable `price_gt_1M`\n",
    "numerical_cols = [col for col in range(0,18) if col not in categorical_cols]\n",
    "numerical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb25f3-5980-4ddd-9c60-baba45ea6449",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 4 - Logistic regression models\n",
    "\n",
    "You are going to build a few different logistic regression models using all of the variables in our housing dataset. For each of these models you will:\n",
    "\n",
    "- Create a pipeline to do the preprocessing (the scaling and encoding) and the modeling (we did this in the Pump it Up project)\n",
    "- I'll be giving you different specifications and hyperparameter parameter settings to try\n",
    "- You'll be scoring the models on overall accuracy for both the training and test data. Discuss any evidence of overfitting or underfitting as well as how the model does in comparison to the null model.\n",
    "- There will be some additional tasks/questions for each model - details below\n",
    "\n",
    "**IMPORTANT** You always should put summary comments in one or more markdown cells. Do **NOT** write them as comments in a code cell. The whole point of Jupyter notebooks is to be able to mix markdown cells with code cells. Yes, you should also include code comments but those are different than analysis comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a04b28-26b4-4082-9f60-045907de9a03",
   "metadata": {},
   "source": [
    "#### Model 0: The null model\n",
    "\n",
    "We always start with the simplest possible model and we call it the *null model*. For binary classification models, the null model is usually just to predict that each observation will fall into whichever class is most prevalent. In other words, what would be the performance of a model in which we just predict 0 for everyone? There's no need to fit a model, just compute the accuracy for train and test if everyone was classified as 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7aef76-474d-43e9-aede-1145f6b706b6",
   "metadata": {},
   "source": [
    "#### Model 1: Ridge regression with C=1.0\n",
    "\n",
    "Build a ridge regression model to predict `price_gt_1M` and use the default value of `C=1.0`. I used the following additional options with the `LogisticRegression` model - `solver='saga', max_iter=2000`. Feel free to change these if you want. AFter fitting the model, compute its accuracy score for training and test and write out a little summary (f-strings are useful). Here's an example:\n",
    "\n",
    "    Training score: 0.974\n",
    "    Test score: 0.971\n",
    "\n",
    "Create confusion matrices for both training and test.\n",
    "\n",
    "Also, create a plot of the coefficients (as we did in the notes). If you want to use that `coef_plot` function we used in the notes, you'll have\n",
    "to make a few modifications because we only have one set of coefficients (since we have a binary classification problem as opposed to a 3-class problem in Pump it Up)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3e920b-82cf-4f4d-84a6-85215716ddd8",
   "metadata": {},
   "source": [
    "#### Model 2: Lasso regression with C=1.0\n",
    "\n",
    "Same as Model 1, but use lasso regression instead of ridge regression. Create the same outputs and compare the performance to the ridge regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a136908d-b40c-4a07-8ef4-af996ac9de6f",
   "metadata": {},
   "source": [
    "#### Model 3: Lasso regression with C=0.01\n",
    "\n",
    "Fit another lasso regression but use `C=0.01`. Does this enforce more or less regularization? Create the same outputs and compare the performance to the first two models. Discuss why the plot looks so different than the previous plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14717178-8781-4a93-90ea-2c2ff3b87406",
   "metadata": {},
   "source": [
    "#### Model 4: Lasso regression with optimal C value\n",
    "\n",
    "Now use `LogisticRegressionCV` to fit a model and let sklearn determine the optimal `C` value to use. Again, compute score and confusion matrices. Also, print out the optimal value of `C`. Does regularization help for this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4730d9-d031-49de-a02d-fa4d91f1ff02",
   "metadata": {},
   "source": [
    "### Task 5 - Random forest model\n",
    "Now fit a random forest model to predict `price_gt_1M`. As we did above, for both train and test, compute the accuracy score, create a confusion matrix, and discuss the performance relative to your logistic regression models. Obviously you do not need to create a coefficient plot (why not?)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70793e38-4f88-4777-82a7-7db804c1a77d",
   "metadata": {},
   "source": [
    "### Task 6 - a little error exploration (more challenging)\n",
    "\n",
    "This will challenge your pandas and your general data manipulation skills. Just give it your best shot. If you don't get, you don't get it. It doesn't require much code - just the right code. :)\n",
    "\n",
    "I also include another data file called `kc_house_data_regression.csv` in which the target variable is `price`. Everything else is exactly the same, including the order of the rows. So, here's your challenge. Using Model 2 (the lasso model with `C=1.0`), start by using the `predict` method to generate an array of predictions for the original test data. Obviously, some of the predictions are correct and some of them are not. It would be interesting to know more about the kinds of errors our model is making. We can see some things from the confusion matrix. However, since we don't have the actual `price` value, it's hard to visualize how the errors relate to it. For example, are we only making errors when the price is really close to 1 million? One way to visualize this is to create a histogram of the actual prices **only for those rows in test that we got wrong**. What makes this tricky? A few things:\n",
    "\n",
    "* As I already mentioned, `price` is not in our original data but is in the `kc_house_data_regression.csv` dataset. Remember, other than the target variable, this dataset is identical (including the index) to the one we used above for classification.\n",
    "* We partitioned the classification dataset into training and test datasets.\n",
    "* In order to create the histogram, we simply need a Series (or array) of `price` values corresponding to the predictions in test that we got wrong.\n",
    "\n",
    "**HINTS** \n",
    "\n",
    "* The pandas `join` method will come in handy.\n",
    "* The pandas `.loc` selector can take a boolean array as an input for selecting rows or columns. Using one to select rows is quite useful for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a026c076",
   "metadata": {},
   "source": [
    "## Optional Hacker Extra Credit tasks\n",
    "I always like to include some extra credit tasks for those who want to push themselves a little further. For this problem, consider doing one or more of the following:\n",
    "\n",
    "* Try out the [Histogram based Gradient Boosting Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html?highlight=histogram%20based%20gradient%20boosting%20classifier) shown in the optional materials at the end of Module 2. Compare its performance to logistic regression and the random forest.\n",
    "* I also include another data file called `kc_house_data_regression.csv` in which the target variable is `price`. Use sklearn's `LassoCV` to find a good regression model for predicting `price`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca32e527",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "You should simply compress your entire project folder as either a zip file or a tar.gz file (do **NOT** ever use WinRAR to create rar files in this class). Note that when you do this, your \"hidden\" `.git` folder will get included. So, I'll be able to tell that you put the project under version control and I'll be able to look at your project folder structure. Before compressing the project folder to submit it:\n",
    "\n",
    "* make sure all of your notebooks and other files are in the main project folder and have good filenames,\n",
    "* make sure you've committed all of your changes (git),\n",
    "* upload your compressed folder in Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a0ad2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aap]",
   "language": "python",
   "name": "conda-env-aap-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
